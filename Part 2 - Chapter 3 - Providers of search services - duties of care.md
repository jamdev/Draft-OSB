#### CHAPTER 3

#### PROVIDERS OF SEARCH SERVICES: DUTIES OF CARE


Search services: duties of care

**17 Providers of search services: duties of care**


(1) Subsections (2) and (3) apply to determine which of the duties set out in this
Chapter apply in relation to a particular regulated search service.


(2) All providers of regulated search services must comply with the following
duties in relation to each such service—
(a) the illegal content risk assessment duty (see section 19(1)),
(b) each of the illegal content duties (see section 21),
(c) the duty to protect rights to freedom of expression and privacy (see
section 23),
(d) the duties about reporting and redress set out in—
(i) section 24(2)(a), and
(ii) section 24(3) and (5) so far as relating to subsection (4)(a)(i), (b)
or (c)(i) of that section, and
(e) each of the record-keeping and review duties (see section 25).
(3) In addition, all providers of regulated search services that are likely to be
accessed by children must comply with the following duties in relation to each
such service—
(a) the children’s risk assessment duty (see section 19(2)),
(b) each of the duties to protect children’s online safety (see section 22),
and
(c) the duties about reporting and redress set out in—
(i) section 24(2)(b), and
(ii) section 24(3) and (5) so far as relating to subsection (4)(a)(ii) or
(c)(ii) of that section.

**18 Duties of care: supplementary**


(1) A duty set out in this Chapter which must be complied with in relation to a
search service extends only to—
(a) the design and operation of the service in the United Kingdom, or
(b) in the case of a duty that is expressed to apply in relation to users of a
service, the design and operation of the service as it affects United
Kingdom users of the service.


(2) A duty set out in this Chapter which must be complied with in relation to a
search service does not extend to—
(a) content present on the website of a recognised news publisher (see
section 40), or
(b) content, that may be encountered via search results, that—
(i) reproduces in full an article or written item that was originally
published by a recognised news publisher (and is not a
screenshot or photograph of that article or item or of part of it),
(ii) is a recording of an item originally broadcast by a recognised
news publisher (and is not an excerpt of such a recording), or
(iii) is a link to a full article or written item originally published by
a recognised news publisher, or to a full recording of an item
originally broadcast by a recognised news publisher.


(3) Where duties in this Chapter must be complied with in relation to a search
engine forming part of a user-to-user service (see section 5(6)), the references
in subsections (1) and (2) to a search service are to be read as references to the
search engine.


Risk assessments

**19 Risk assessment duties**


All services


(1) The “illegal content risk assessment duty” is a duty—
(a) to carry out an illegal content risk assessment at a time set out in section
20,
(b) to keep an illegal content risk assessment up to date, including when
OFCOM make any significant change to a risk profile that relates to
services of the kind in question, and
(c) to carry out a further illegal content risk assessment before making any
significant change to any aspect of the design or operation of a service
to which such an assessment is relevant.


Services likely to be accessed by children


(2) The “children’s risk assessment duty” is a duty—
(a) to carry out a children’s risk assessment at a time set out in section 20,
(b) to keep a children’s risk assessment up to date, including when
OFCOM make any significant change to a risk profile that relates to
services of the kind in question, and
(c) to carry out a further children’s risk assessment before making any
significant change to any aspect of the design or operation of a service
to which such an assessment is relevant.


Definitions


(3) An “illegal content risk assessment” of a service of a particular kind means an
assessment to identify, assess and understand such of the following as appear
to be appropriate, taking into account the risk profile that relates to services of
that kind—
(a) the level of risk of individuals who are users of the service encountering
the following in or via search results—
(i) terrorism content,
(ii) CSEA content,
(iii) priority illegal content, and
(iv) other illegal content,
taking into account (in particular) risks presented by algorithms used
by the service, and the way that the service indexes, organises and
presents search results;
(b) the level of risk of functionalities of the service facilitating individuals
encountering illegal content in or via search results, identifying and
assessing those functionalities that present higher levels of risk;
(c) the nature, and severity, of the harm that might be suffered by
individuals from the matters identified in accordance with paragraphs
(a) and (b);
(d) how the design and operation of the service (including the business
model, governance and other systems and processes) may reduce or
increase the risks identified.


(4) A “children’s risk assessment” of a service of a particular kind means an
assessment to identify, assess and understand such of the following as appear
to be appropriate, taking into account the risk profile that relates to services of
that kind—
(a) the level of risk of children who are users of the service encountering
the following in or via search results—
(i) each kind of primary priority content that is harmful to children
(with each kind separately assessed),
(ii) each kind of priority content that is harmful to children (with
each kind separately assessed), and
(iii) non-designated content that is harmful to children,
giving separate consideration to children in different age groups, and
taking into account (in particular) risks presented by algorithms used
by the service and the way that the service indexes, organises and
presents search results;
(b) the level of risk of functionalities of the service facilitating children
encountering content that is harmful to children in or via search results,
identifying and assessing those functionalities that present higher
levels of risk;
(c) the nature, and severity, of the harm that might be suffered by children
from the matters identified in accordance with paragraphs (a) and (b),
giving separate consideration to children in different age groups;
(d) how the design and operation of the service (including the business
model, governance and other systems and processes) may reduce or
increase the risks identified.


(5) In this section references to risk profiles are to risk profiles included in
OFCOM’s guidance about risk assessments (see section 62).

**20 Timing of risk assessment under section 19**


(1) In the case of a regulated search service which is in operation immediately
before the relevant day, a risk assessment must be carried out within the period
of three months beginning with that day, unless extra time is allowed by
agreement with OFCOM.


(2) In the case of a regulated search service which begins operating on or after the
relevant day, a risk assessment must be carried out before United Kingdom
users are able to access the service.


(3) In the case of a search service which, having previously not been a regulated
search service, becomes a regulated search service, a risk assessment must be
carried out—
(a) before United Kingdom users are able to access the service, or
(b) if such users were already able to access the service, as soon as
reasonably practicable after the service becomes a regulated service.


(4) In this section “the relevant day” means—
(a) if OFCOM’s report of their risk assessment under section 61 and
OFCOM’s guidance about risk assessments under section 62 are first
published on the same day, that day, or
(b) if that report and that guidance are first published on different days, the
later of those days.


(5) In this section “risk assessment” means a risk assessment under section 19(1)(a)
or (2)(a).


Safety duties

**21 Safety duties about illegal content**


(1) The “illegal content duties” in relation to search services are the duties set out
in this section.


(2) A duty, in relation to a service, to take proportionate steps to mitigate and
effectively manage the risks of harm to individuals, as identified in the most
recent illegal content risk assessment of the service.

(3) A duty to operate a service using proportionate systems and processes
designed to minimise the risk of individuals encountering the following in or
via search results—
(a) priority illegal content;
(b) other illegal content that the provider knows about (having been
alerted to it by another person or become aware of it in any other way).


(4) A duty to specify clearly in a publicly available statement details of policies
and procedures designed to protect individuals from illegal content.


(5) A duty to apply the policies and procedures mentioned in that statement
consistently.


(6) In determining whether a step, system or process is proportionate for the
purposes of this section, the following must be taken into account—
(a) all the findings of the most recent illegal content risk assessment
(including as to levels of risk and as to nature, and severity, of potential
harm to individuals), and
(b) the size and capacity of the provider of a service.


(7) In this section “illegal content risk assessment” has the meaning given by
section 19(3).


(8) See also, in relation to duties under this section, section 23(2) (duty about rights
to freedom of expression and privacy).

**22 Safety duties for services likely to be accessed by children**


(1) The “duties to protect children’s online safety” in relation to search services are
the duties set out in this section.


(2) A duty, in relation to a service, to take proportionate steps to—
(a) mitigate and effectively manage the risks of harm to children in
different age groups, as identified in the most recent children’s risk
assessment of the service, and
(b) mitigate the impact of harm arising to children in different age groups
from content that is harmful to children encountered in or via search
results of the service.


(3) A duty to operate a service using proportionate systems and processes
designed to—
(a) minimise the risk of children of any age encountering primary priority
content that is harmful to children in or via search results;
(b) minimise the risk of children in age groups judged to be at risk of harm
from other content that is harmful to children (or from a particular kind
of such content) encountering it in or via search results.


(4) A duty to specify clearly in a publicly available statement details of policies
and procedures designed to protect children from—
(a) primary priority content that is harmful to children (with each kind of
primary priority content separately covered),
(b) priority content that is harmful to children (with each kind of priority
content separately covered), and
(c) non-designated content that is harmful to children.
(5) A duty to apply the policies and procedures mentioned in that statement
consistently.


(6) In determining whether a step, system or process is proportionate for the
purposes of this section, the following must be taken into account—
(a) all the findings of the most recent children’s risk assessment (including
as to levels of risk and as to nature, and severity, of potential harm to
children), and
(b) the size and capacity of the provider of a service.


(7) So far as a duty in this section relates to non-designated content that is harmful
to children, the duty is to be taken to extend only to addressing risks of harm
from the kinds of such content that have been identified in the most recent
children’s risk assessment (if any have been identified).


(8) The reference in subsection (3)(b) to children in age groups judged to be at risk
of harm from content that is harmful to children is a reference to children in age
groups judged to be at risk of such harm as assessed by the provider of a
service in the most recent children’s risk assessment of the service.


(9) The duties in this section extend only to such parts of a service as it is possible
for children to access.
Section 26(3) applies for the purposes of this subsection as it applies for the
purposes of an assessment under section 26.


(10) In this section “children’s risk assessment” has the meaning given by section
19(4).


(11) See also, in relation to duties under this section, section 23(2) (duty about rights
to freedom of expression and privacy).


Freedom of expression and privacy

**23 Duty about rights to freedom of expression and privacy**


(1) The “duty to protect rights to freedom of expression and privacy” in relation to
search services is the duty set out in this section.


(2) A duty to have regard to the importance of—
(a) protecting the rights of users and interested persons to freedom of
expression within the law, and
(b) protecting users from unwarranted infringements of privacy,
when deciding on, and implementing, safety policies and procedures.


(3) In this section “safety policies and procedures” means policies and procedures
designed to secure compliance with—
(a) any of the Chapter 3 safety duties, or
(b) any of the duties set out in section 24 (reporting and redress).


User reporting and redress

**24 Reporting and redress duties**


(1) The duties about reporting and redress in relation to search services, as
referred to in section 17, are the duties set out in this section.


(2) A duty to operate a service using systems and processes that allow users and
affected persons to easily report content of the following kinds encountered in
or via search results—
(a) content which they consider to be illegal content;
(b) content which they consider to be content that is harmful to children.


(3) A duty to operate a complaints procedure in relation to a service that—
(a) allows for complaints of the kinds mentioned in subsection (4) to be
made,
(b) provides for appropriate action to be taken by the provider of the
service in response to such complaints, and
(c) is easy to access, easy to use (including by children) and transparent.


(4) The kinds of complaints are—
(a) complaints by users and affected persons about content of the
following kinds encountered in or via search results—
(i) content which they consider to be illegal content;
(ii) content which they consider to be content that is harmful to
children;
(b) complaints by users and affected persons if they consider that—
(i) the provider is not complying with a Chapter 3 safety duty that
applies in relation to the service;
(ii) the provider is not complying with the duty set out in section
23;
(c) complaints by an interested person if—
(i) the provider of a search service takes steps in order to comply
with duties under section 21 (safety duties about illegal content)
that result in content relating to that interested person no longer
appearing in search results or being given a lower priority in
search results;
(ii) the provider of a search service takes steps in order to comply
with duties under section 22 (safety duties for services likely to
be accessed by children) that result in content relating to that
interested person no longer appearing in search results or being
given a lower priority in search results.


(5) A duty to make the policies and procedures that govern the handling and
resolution of complaints as mentioned in subsection (4) publicly available and
easily accessible (including to children).


(6) In this section “affected person” means a person, other than a user of the service
in question, who is in the United Kingdom and who is—
(a) the subject of the content,
(b) a member of a class or group of people with a certain characteristic (or
combination of characteristics) targeted by the content,
(c) a parent of, or other adult with responsibility for, a child who is a user
of the service or is the subject of the content, or
(d) an adult providing assistance in using the service to another adult who
requires such assistance, where that other adult is a user of the service
or is the subject of the content.


(7) See also, in relation to duties under this section, section 23(2) (duty about rights
to freedom of expression and privacy).

Record-keeping and review

**25 Record-keeping and review duties**


(1) The “record-keeping and review duties” in relation to search services are the
duties set out in this section.


(2) A duty to make and keep a written record of every risk assessment carried out
under section 19.


(3) A duty to make and keep a written record of any steps taken to comply with a
relevant duty other than steps which—
(a) are described in a code of practice and recommended for the purposes
of compliance with the duty in question, and
(b) apply in relation to the provider and the service in question.


(4) A duty to review compliance with the relevant duties in relation to a service—
(a) regularly, and
(b) as soon as reasonably practicable after making any significant change
to any aspect of the design or operation of the service.


(5) Where OFCOM consider it to be appropriate, OFCOM may, in relation to a
particular search service, exempt the provider of that service from—
(a) the duty set out in subsection (2),
(b) the duty set out in subsection (3), or
(c) the duties set out in subsections (2) and (3).


(6) OFCOM must publish details of any exemption under subsection (5).


(7) In this section—
“code of practice” means a code of practice published under section 34;
“relevant duties” means—
(a) the Chapter 3 safety duties, and
(b) the duties set out in section 24 (reporting and redress).

#### EXPLANATORY NOTES FOR THIS SECTION

Chapter 3: Providers of search services: duties of care

Clause 17: Providers of search services: duties of care

This clause is to be used to determine the duties which apply to all regulated
search services (subsection (2)), and additional duties which are to apply where a
regulated search service is likely to be accessed by children (subsection (3)).
All regulated search service providers must comply with the duties in relation
to the illegal content risk assessment duty, each of the safety duties about illegal
content, the duty to protect rights to freedom of expression and privacy, the user
reporting and redress duties as they relate to illegal content and the Chapter 3 safety
duties, and the record-keeping and review duties.
These explanatory notes relate to the Online Safety Bill as published in draft on 12 May 2021 (Bill CP 405)
Where a search service is likely to be accessed by children (as should be
determined by a service provider according to the assessment in clause 26 ), these
services must comply with the children’s risk assessment duty, each of children’s
safety duties, and the duties about reporting and redress that apply in relation to
content that is harmful to children.
Clause 18: Duties of care: supplementary

Subsection (1) sets out that the duties described in this chapter are only
applicable to the design and operation of search services so far as these may affect
users and others who are in the United Kingdom.
To ensure the protection of journalistic freedoms, subsection (2) clarifies that
the duties on search services are not applicable to content from recognised news
publishers.
Subsection (3) provides that when a search engine forms part of a user-to-
user service, the provisions in subsections (1) and (2) should be taken as applying to
the search engine.
Clause 19: Risk assessment duties

This clause sets out the duties on regulated search services to assess risks
arising from illegal content and content which is legal but harmful to children.
Subsection (1) places a duty on search services to undertake an illegal
content risk assessment. Search services must undertake this within the time periods
set out in clause 20. They must keep their risk assessment up-to-date and carry out a
further risk assessment before making any significant changes to their service.
Subsection (2) refers to the children’s risk assessment that services likely to
be accessed by children must undertake. Search services must undertake this in
accordance with the time periods set out in clause 20. They must keep their risk
assessment up-to-date and carry out a further risk assessment before making any
significant changes to their service.
Subsection (3) provides further detail on what would form part of an illegal
content risk assessment. Service providers are required to identify, assess and
understand the risk factors listed in this subsection (as appropriate), having regard to
the risk profiles that relate to a service of its kind (risk profiles are those contained in
OFCOM’s guidance about risk assessments (clause 62)). The risk factors include the
level of risk of users encountering terrorism content, child sexual exploitation and
abuse (CSEA) content, priority illegal content, and other illegal content which can be
accessed either on or via the search results of a search service. Service providers
should take into account risks presented by algorithms and the way in which the
service indexes, organises and presents search results.
Subsection (4) sets out the requirements of a children’s risk assessment.
Service providers are required to identify, assess and understand the risk factors
listed in this subsection (as appropriate), having regard to the risk profiles that relate
to a service of its kind (risk profiles are those contained in OFCOM’s guidance about
These explanatory notes relate to the Online Safety Bill as published in draft on 12 May 2021 (Bill CP 405)
risk assessments (clause 62)). The risk factors include the level of risk of children
coming across primary priority, priority or non designated content in or via search
results on the search service. Each kind of primary priority, priority and non
designated content must be separately assessed. Further, the service provider must
also give separate consideration to children in different age groups and take into
account risks presented by algorithms used by the service and how the service
indexes, organises and presents search results.
Clause 20: Timing of risk assessment under section 19

This clause sets out the time periods within which a regulated search service
provider must carry out the risk assessments referred to above. The time period will
start to run from the day on which OFCOM publishes its report on its risk assessment
under clause 61 and its guidance about risk assessments under clause 62, if these
are published on different days whichever is the later of those days: see subsection
(4). This is referred to as the “relevant day”.
If the regulated search service was already operating immediately before the
relevant day, they must carry out their risk assessments within three months unless
they agree extra time with OFCOM: subsection (1). If the service provider begins
operating after the relevant day then the risk assessment must be carried out either
before UK users are able to access the service: subsection (2). In the case of a user-
to-user service which was not previously regulated but then becomes regulated, the
relevant risk assessments must be carried out before users in the UK can access the
service or, if UK users can already access the service, as soon as possible after the
service becomes regulated: sub-section (3).
Clause 21: Safety duties about illegal content

This clause imposes duties on regulated search services with regards to
illegal content.
Subsection (2) requires service providers to take proportionate steps to
mitigate and manage the risks of harm to individuals, as identified in the most recent
illegal content risk assessment of the service.
Subsection (3) requires service providers to ensure they have proportionate
systems and processes to minimise the risk of users encountering either priority
illegal content or other illegal content that the provider knows about on their services
because they have been alerted to it or they become aware of it in some other way.
Subsection (4) requires service providers to provide a publicly available
statement explaining their policies and procedures for protecting users from illegal
content. Subsection (5) requires those policies and procedures to be applied
consistently and transparently.
Subsection (6) specifies that whether steps, systems and processes are
proportionate is determined by the levels of risk identified in the risk assessment and
the service provider’s size and capacity. In practice, this means that the expectations
will be different for a large, high risk service compared to a small, low risk service.
These explanatory notes relate to the Online Safety Bill as published in draft on 12 May 2021 (Bill CP 405)
Subsection (8) links the duties about users’ rights to freedom of expression
and privacy in clause 23(2) to the illegal content safety duty in this clause.
Clause 22: Safety duties for services likely to be accessed by children

This clause imposes duties on regulated search services with regards to
content that is harmful to children. As established in clause 17, regulated search
services that are likely to be accessed by children must comply with these duties.
Subsection (2) requires service providers to:
a. take proportionate steps to manage the risk of harm to children in different
age groups from risks identified in the children’s risk assessment as carried
out under clause 19; and
b. mitigate the impact of harm to children in different age groups from content
that is harmful to children which they may encounter in or via search results.
Subsection (3) requires service providers to use proportionate systems and
processes to minimise the risk of children of any age from encountering (in or via
search results) primary priority content that is harmful to children. In the case of other
content that is harmful to children, to minimise the risk of children encountering such
content in or via search results where their age puts them at risk of harm, for
example, protecting younger children encountering violent content which is not
appropriate for their age.
Subsection (4) requires service providers to specify clearly in a publicly
available statement details of their policies and procedures designed for protecting
children from encountering primary priority content on their service and priority
content that is harmful for children on their service. It also requires providers to set
out how children are protected from encountering other content that would satisfy the
definition of being harmful to children (see clause 45). Providers must then apply
these policies and procedures consistently (subsection (5)).
Subsection (6) specifies that whether steps, systems and processes are
proportionate is determined by the levels of risk identified in the children’s risk
assessment and the service provider’s size and capacity.
Subsection (7) clarifies that services are only required to fulfil the duty in this
section in relation to non-designated content (i.e. neither primary priority content nor
priority content) if risks from the kinds of non-designated content that have been
identified in the most recent children’s risk assessment.
Subsection (8) clarifies that that the reference to ‘age groups judged to be at
risk of harm’ are to those assessed as being so in the service provider’s most recent
children’s risk assessment.
Subsection (9) clarifies that the above duties only apply to parts of the service
accessible to children, in line with the assessment on children’s access set out in
clause 26.
These explanatory notes relate to the Online Safety Bill as published in draft on 12 May 2021 (Bill CP 405)
Subsection (10) is self-explanatory.
Subsection (11) links the duties about users’ rights to freedom of expression
and privacy in clause 23(2) to the safety duties for services likely to be accessed by
children in this section.
Clause 23: Duty about rights to freedom of expression and privacy

This clause sets out the duties on regulated search services to have regard to
the importance of protecting users’ rights to freedom of expression and protecting
users from unwarranted infringement of privacy when designing and implementing
their safety policies and procedures. References to freedom of expression within the
law include common law rights.
Clause 24: Reporting and redress duties

This clause sets out the user reporting and redress mechanisms which apply
to regulated search service providers.
Subsection (2) places a duty on service providers to have systems and
processes in place that allow users or affected persons (as defined in subsection (6))
to report content encountered in or via search results that the user or affected person
considers to be (a) illegal and (b) harmful to children (where that content can be
accessed by a child).
Subsection (3) places a duty on the service provider to have a complaints
procedure that is easy to access, easy to use and transparent, and that provides for
the service provider to take appropriate action in response to the complaints set out
in subsection (4). Where applicable, the complaints procedure must also be easy to
access and use including for children who may wish to complain.
Subsection (4) outlines the kinds of complaints that subsection (3) applies to.
This includes complaints about content that is considered to be illegal or harmful to
children, which is encountered in or via search results, as well as complaints about a
provider not complying with their safety duties or their duties in relation to freedom of
expression and privacy. This also includes complaints by an interested party about
action a service provider has taken (in complying with their safety duties) which
results in content relating to an interested party no longer appearing in search results
or being given a lower priority in the search results.
Subsection (5) places a duty on service providers to make their complaints
policies and procedures publicly available and easy to access. This is to ensure that
users, affected persons, and interested persons can easily find the complaints
policies and procedures and that the process is transparent.
Subsection (6) defines an ‘affected person’ as someone who is in the United
Kingdom other than a user of the service. An affected person is either:
a. The subject of the content.
These explanatory notes relate to the Online Safety Bill as published in draft on 12 May 2021 (Bill CP 405)
b. A member of a class or group of people with a certain characteristic targeted
by the content.
c. A parent or other adult with responsibility for a child who is a user of the
service or the subject of that content.
d. A person who is providing assistance in using the service to another adult
who requires such assistance and who is a user of the service or the subject
of the content.
Subsection (7) links the duties about users’ rights to freedom of expression
and privacy in clause 23(2) to the duties in this clause.
Clause 25: Record-keeping and review duties

This clause sets out the record-keeping and review obligations that apply to
the risk assessment duties, safety duties and the duties on reporting and redress
above.
Subsection (2) requires service providers to keep a written record of the risk
assessments carried out under clause 19.
Subsection (3) requires service providers to keep a written record of the steps
they have taken to comply with the safety duties and reporting and redress duties
that are not provided for in the codes of practice. This requirement does not apply
where a service provider has followed steps set out in a code of practice.
Subsection (4) sets out a duty on service providers to review their compliance
with the safety duties and duties on reporting and redress regularly and after making
any significant changes to their service.
Subsection (5) provides OFCOM with the ability to exempt certain providers
from the need to keep written records. It is envisaged that this could be used where
there are small, low risk services. Subsection (6) requires OFCOM to publish the
details of any such exemption.

##### DELEGATED POWERS MEMORANDUM

CHAPTER 3: PROVIDERS OF SEARCH SERVICES: DUTIES OF CARE
Clause 25(5): Record-keeping and review duties

Power conferred on: OFCOM
Power exercised by: Decision
Parliamentary procedure: None

Context and purpose

The framework requires that regulated services undertake recording keeping and
review duties. Those duties for search services are set out in clause 25. Those duties
are:
○ A duty to make and keep a written record of every risk assessment carried
out under clause 19 (subsection (2));
○ A duty to make and keep a written record of any steps taken to comply with
a relevant duty. This duty does not include keeping a record of steps which
are described in a code of practice and recommended for the purposes of
compliance with the duty in question, and apply in relation to the provider
and the service in question (subsection (3)); and
○ A duty to review compliance with the Chapter 3 safety duties in relation to a
service regularly, and as soon as reasonably practicable after making any
significant change to any aspect of the design or operation of the service
(subsection (4)).
The record-keeping and review duties set out above allow effective scrutiny of
regulated services and are central to ensuring that regulated services operate
transparently and in compliance with the regulatory framework.
However, these duties are extensive and may prove to be excessive in specific
cases. Under subjection (5), where OFCOM consider it to be appropriate, OFCOM
may, in relation to a particular search service, exempt the provider of that service from
the duty set out in subsection (2), the duty set out in subsection (3), or the duties set
out in subsections (2) and (3). Under subsection (6) OFCOM must publish details of
any such exemption.
Justification for the power

This power enabling OFCOM to exempt a particular service from the record-keeping
and review duties will allow OFCOM to remain responsive and adapt to changes in
the regulatory landscape. This will help to ensure that the regime remains effective
and proportionate.
Delegating this power will allow exemptions to be provided when the framework is
operational, and OFCOM can use its full resources and expertise to assess what
expectations are proportionate for particular services to comply with.
This power is limited and its scope is clearly set out in primarily legislation. This power
will not allow services to be removed from scope entirely, nor will it reduce the steps
companies must take to comply with the wider requirements of the regulatory
framework. It only allows the record-taking steps companies must undertake to be
reduced where it is considered appropriate by OFCOM.
Justification for the procedure

OFCOM must publish the details of any exemption granted under subsection (5). This
will ensure that OFCOM’s exercise of this power can be scrutinised.
Since these provisions are concerned with operational and administrative matters in
the context of how the regulator intends to use its powers, the provision to be made is
administrative rather than legislative in character. Therefore, no Parliamentary
procedure is considered necessary.
